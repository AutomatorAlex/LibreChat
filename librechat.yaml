version: 1.2.1
# File storage strategy - use firebase for Firebase Storage
fileStrategy: firebase
interface:
  endpointsMenu: true
  modelSelect: true
  parameters: true
  sidePanel: true
  presets: true
  prompts: true
  bookmarks: true
  multiConvo: true
  agents: true
  temporaryChat: true
  runCode: true

endpoints:
  agents:
    # Default recursion depth for agents, increased from 25 to 50
    recursionLimit: 50
    # Maximum recursion depth for agents, set to 100 for complex tool chains
    maxRecursionLimit: 100
  custom:
    # Cerebras-optimized models via OpenRouter
    - name: "OpenRouter (Cerebras)"
      apiKey: ${OPENROUTER_KEY}
      baseURL: https://openrouter.ai/api/v1
      iconURL: "https://openrouter.ai/favicon.ico"
      models:
        fetch: false
        default:
          # Cerebras-supported models only
          - meta-llama/llama-3.3-70b-instruct
          - meta-llama/llama-3.1-70b-instruct
          - meta-llama/llama-3.1-8b-instruct

      titleConvo: true
      titleModel: openai/gpt-4.1-mini:nitro
      dropParams:
        - stop
      modelDisplayLabel: "OpenRouter (Cerebras)"
      # Force all requests through Cerebras
      providerRouting:
        order:
          - cerebras
        allow_fallbacks: false

    # Anthropic models via OpenRouter
    - name: "Anthropic (OpenRouter)"
      apiKey: ${OPENROUTER_KEY}
      baseURL: https://openrouter.ai/api/v1
      models:
        fetch: false
        default:
          - anthropic/claude-sonnet-4:nitro
          - anthropic/claude-opus-4:nitro
          - anthropic/claude-3.7-sonnet:nitro
      titleConvo: true
      titleModel: openai/gpt-4.1-mini:nitro
      dropParams:
        - stop
      modelDisplayLabel: "Anthropic"
      plugins:
        - id: web
          max_results: 15
      agents:
        code: true
        tools: true

    # OpenAI models via OpenRouter
    - name: "OpenAI (OpenRouter)"
      apiKey: ${OPENROUTER_KEY}
      baseURL: https://openrouter.ai/api/v1
      models:
        fetch: false
        default:
          - openai/o3-pro:nitro
          - openai/gpt-4.1:nitro
          - openai/gpt-4.1-mini:nitro
          - openai/gpt-4.1-nano:nitro
          - openai/gpt-4.5-preview:nitro
          - openai/o1-preview:nitro
          - openai/o1-mini:nitro
          - openai/o4-mini:nitro
          - openai/o4-mini-high:nitro
          - openai/gpt-4o:nitro
      titleConvo: true
      titleModel: openai/gpt-4.1-nano:nitro
      dropParams:
        - stop
      modelDisplayLabel: "OpenAI"
      plugins:
        - id: web
          max_results: 15
      agents:
        code: true
        tools: true

    # Google models via OpenRouter
    - name: "Google (OpenRouter)"
      apiKey: ${OPENROUTER_KEY}
      baseURL: https://openrouter.ai/api/v1
      models:
        fetch: false
        default:
          - google/gemini-2.5-flash:nitro
          - google/gemini-2.5-pro:nitro
      titleConvo: true
      titleModel: openai/gpt-4.1-mini:nitro
      dropParams:
        - stop
      modelDisplayLabel: "Google"
      plugins:
        - id: web
          max_results: 15
      agents:
        code: true
        tools: true

    # Mistral models via OpenRouter
    - name: "Mistral (OpenRouter)"
      apiKey: ${OPENROUTER_KEY}
      baseURL: https://openrouter.ai/api/v1
      models:
        fetch: false
        default:
          - mistralai/mistral-large-2411:nitro
          - mistralai/mistral-large-2407:nitro
          - mistralai/mistral-medium-3:nitro
          - mistralai/mistral-small-3.1-24b-instruct:nitro
          - mistralai/mistral-small-24b-instruct-2501:nitro
          - mistralai/mistral-nemo:nitro
          - mistralai/mistral-7b-instruct:nitro
      titleConvo: true
      titleModel: openai/gpt-4.1-mini:nitro
      dropParams:
        - stop
      modelDisplayLabel: "Mistral"
      plugins:
        - id: web
          max_results: 15
      agents:
        code: true
        tools: true

    # Meta Llama models via OpenRouter
    - name: "Meta Llama (OpenRouter)"
      apiKey: ${OPENROUTER_KEY}
      baseURL: https://openrouter.ai/api/v1
      models:
        fetch: false
        default:
          - meta-llama/llama-4-maverick:nitro
          - meta-llama/llama-3.3-70b-instruct:nitro
          - meta-llama/llama-3.2-90b-vision-instruct:nitro
          - meta-llama/llama-3.2-11b-vision-instruct:nitro
          - meta-llama/llama-3.1-405b-instruct:nitro
          - nvidia/llama-3.1-nemotron-ultra-253b-v1:nitro
      titleConvo: true
      titleModel: openai/gpt-4.1-mini:nitro
      dropParams:
        - stop
      modelDisplayLabel: "Meta Llama"
      plugins:
        - id: web
          max_results: 15
      agents:
        code: true
        tools: true

    # xAI models via OpenRouter
    - name: "xAI (OpenRouter)"
      apiKey: ${OPENROUTER_KEY}
      baseURL: https://openrouter.ai/api/v1
      models:
        fetch: false
        default:
          - x-ai/grok-3:nitro
          - x-ai/grok-3-mini:nitro
          - x-ai/grok-4:nitro
      titleConvo: true
      titleModel: openai/gpt-4.1-mini:nitro
      dropParams:
        - stop
      modelDisplayLabel: "xAI"
      plugins:
        - id: web
          max_results: 15
      agents:
        code: true
        tools: true

    # Other models via OpenRouter
    - name: "Other Models (OpenRouter)"
      apiKey: ${OPENROUTER_KEY}
      baseURL: https://openrouter.ai/api/v1
      models:
        fetch: false
        default:
          - minimax/minimax-m1:nitro
          - minimax/minimax-m1:extended
      titleConvo: true
      titleModel: openai/gpt-4.1-mini:nitro
      dropParams:
        - stop
      modelDisplayLabel: "Other Models"
      plugins:
        - id: web
          max_results: 15
      agents:
        code: true
        tools: true
  openAI:
    disabled: true

fileConfig:
  endpoints:
    vectorStore:
      type: rag_api
      ragApiUrl: ${RAG_API_URL}

speech:
  tts:
    openai:
      apiKey: ${OPENAI_API_KEY}
      model: tts-1
      voices:
        - alloy
        - echo
        - fable
        - onyx
        - nova
        - shimmer
  stt:
    openai:
      apiKey: ${OPENAI_API_KEY}
      model: whisper-1
  speechTab:
    conversationMode: true
    advancedMode: false
    speechToText:
      engineSTT: external
      languageSTT: English (US)
      autoTranscribeAudio: true
      decibelValue: -45
      autoSendText: 0
    textToSpeech:
      engineTTS: external
      voice: alloy
      languageTTS: en
      automaticPlayback: true
      playbackRate: 1
      cacheTTS: true

mcpServers:
  # Using Netlify Functions with streamable-http transport (perfect for hosted LibreChat!)
  jina:
    type: streamable-http
    url: https://mcps.netlify.app/mcp/jina
    headers:
      X-MCP-API-Key: "${MCP_API_KEY}"
    timeout: 180000
    initTimeout: 15000
    
  thinking:
    type: streamable-http
    url: https://mcps.netlify.app/mcp/thinking
    headers:
      X-MCP-API-Key: "${MCP_API_KEY}"
    timeout: 180000
    initTimeout: 15000

  business-strategy:
    type: streamable-http
    url: https://mcps.netlify.app/mcp/business-strategy
    headers:
      X-MCP-API-Key: "${MCP_API_KEY}"
    timeout: 180000
    initTimeout: 15000
    
  stripe:
    type: streamable-http
    url: https://mcps.netlify.app/mcp/stripe
    headers:
      X-MCP-API-Key: "${MCP_API_KEY}"
    timeout: 180000
    initTimeout: 15000

  # Working N8N MCPs (keep these as SSE)
  n8n-business-tools-mcp:
    type: sse
    url: https://n8n.metamation.net/mcp/12bd30ab-6657-4d89-95f7-5e6c818d81e6/sse
    headers:
      Authorization: "Bearer ${N8N_API_KEY}"
    timeout: 180000
    initTimeout: 15000
    
  n8n-outlook-mcp:
    type: sse
    url: https://n8n.metamation.net/mcp/97a5106e-0b1a-4b61-8818-937f81d6932c/sse
    headers:
      Authorization: "Bearer ${N8N_API_KEY}"
    timeout: 180000
    initTimeout: 15000

# Memory configuration for user memories
memory:
  # Enable memory functionality
  disabled: false
  # Restrict memory keys to specific values to limit memory storage and improve consistency
  validKeys: ["preferences", "work_info", "personal_info", "business_info", "skills", "interests", "context"]
  # Maximum token limit for memory storage
  tokenLimit: 10000
  # Enable personalization features
  personalize: true
  # Memory agent configuration - define inline with OpenRouter
  agent:
    provider: "openrouter"
    model: "openai/gpt-4.1:nitro"
    instructions: "You are a memory management assistant for Alex. Store and manage user information accurately. Focus on remembering user preferences, work information, businesses information, personal details, skills, interests, and conversation context to provide personalized assistance. Business information refers to info relating to Alex's business called METAMATION"
    model_parameters:
      temperature: 0.1

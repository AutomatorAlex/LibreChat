version: 1.2.1 # Or your current LibreChat config version

# Include any other general configurations you need at the top level.
# For example, if you had `cache: true` or `interface` settings.

endpoints:
  custom:
    - name: 'OpenRouter'
      apiKey: '${OPENROUTER_KEY}' # This will use your Render env var for OPENROUTER_KEY
      baseURL: 'https://openrouter.ai/api/v1'
      models:
        fetch: false # Crucial for manually listing the :online model
        default:
          - 'google/gemini-2.5-pro-preview:online'
          - 'anthropic/claude-3.7-sonnet:thinking'
          - 'openai/gpt-4.1'
          # If you use other OpenRouter models, list them here as well:
          # - 'meta-llama/llama-3-70b-instruct'
      titleConvo: true
      titleModel: 'google/gemini-2.5-pro-preview' # Or 'google/gemini-2.5-pro-preview:online'
      dropParams:
        - 'stop'
      modelDisplayLabel: 'OpenRouter'
      agents:
        code: true # Enables the Code Interpreter for this OpenRouter endpoint
    # Example for an OpenAI endpoint, if you were adding one directly (not via OpenRouter)
  openAI: # This is a system-level endpoint key
    # If you have multiple OpenAI accounts or want to label them
    # - name: 'My Personal OpenAI'
    apiKey: '${OPENAI_API_KEY}' # Will use OPENAI_API_KEY from Render env vars
    # organization: '${OPENAI_ORGANIZATION}' # Optional
    # baseURL: 'https://api.openai.com/v1' # Default, can be overridden for proxies
    models:
      default:
        - 'gpt-image-1' # Your specific model for images
        # Add other OpenAI models you want to make available here
        # - 'gpt-4'
        # - 'gpt-3.5-turbo'
      fetch: false # Set to true if you want to dynamically fetch all available models
    titleConvo: true
    titleModel: 'gpt-3.5-turbo' # Or any model suitable for titles
    # modelDisplayLabel: 'OpenAI' # Optional display label
    # iconURL: '/assets/openai.png' # Optional custom icon
    agents:
      code: true # Enables the Code Interpreter globally for this endpoint
      # You can add other agent-related capabilities here if needed in the future
      # e.g., tools: ['Tool1', 'Tool2']

# This should be a top-level key, at the same indentation as 'version' and 'endpoints'
fileConfig:
  endpoints:
    vectorStore:
      type: rag_api
      ragApiUrl: "${RAG_API_URL}" # This will be an env var on your main LibreChat Render service
      # Optional: If you need to specify which embedding model the main app should expect or request
      # This might not be needed if the RAG API handles its embedding model choice entirely.
      # ragEmbeddingModel: "text-embedding-3-small" # Example
  # You can also set global file size limits if needed
  # serverFileSizeLimit: 100 # in MB
  # avatarSizeLimit: 2 # in MB

# ... any other configurations at the end of your file ...
# Ensure there's a newline at the end of the file if it's the last thing.

# Example Actions Object Structure
actions:
  allowedDomains:
    - "swapi.dev"
    - "librechat.ai"
    - "google.com"

# MCP Servers
mcpServers:
  smithery-sequential-thinking: # New name for this server entry
    type: streamable-http # Reverting to streamable-http
    url: "https://server.smithery.ai/@smithery-ai/server-sequential-thinking/mcp?profile=delightful-hyena-GSmzOH&api_key=2889e4fc-ae4b-47c1-b2df-cdcfb187485c" # URL with profile and hardcoded API key
    timeout: 90000

# Definition of custom endpoints
# customEndpoints:
#   - name: "openAI"